{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "import pymongo\n",
    "from googleapiclient.discovery import build\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"*****\")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['youtube_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyDg0lv52ov9xx1tENd9qljGVhkOJbzy0NY'\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to get channel details\n",
    "\n",
    "def channel_details(channel_id):\n",
    "    ch_data = []\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=channel_id  # Use the provided channel_id directly\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(\n",
    "            channel_id=channel_id,\n",
    "            channel_name=response['items'][i]['snippet']['title'],\n",
    "            channel_views=response['items'][i]['statistics']['viewCount'],\n",
    "            channel_type=response['items'][i]['snippet']['customUrl'],\n",
    "            channel_description=response['items'][i]['snippet']['description'],\n",
    "            channel_status=response['items'][i]['snippet']['publishedAt'],\n",
    "            videos_count = response['items'][i]['statistics']['videoCount']\n",
    "        )\n",
    "        ch_data.append(data)\n",
    "    return ch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to get playlist table data directly\n",
    "def playlist_data(channel_id):\n",
    "    pl_data = []\n",
    "\n",
    "    request = youtube.playlists().list(\n",
    "        part = \"snippet\",\n",
    "        channelId = channel_id,\n",
    "        # id = playlist_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channel_id = channel_id,\n",
    "                    playlist_id = response['items'][i]['id'],\n",
    "                    playlist_name = response['items'][i]['snippet']['title']\n",
    "                    )\n",
    "        \n",
    "        pl_data.append(data)\n",
    "    return pl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to get video ids of the channel you entered\n",
    "def channel_videos(channel_id):\n",
    "    video_ids = []\n",
    "\n",
    "    request = youtube.search().list(\n",
    "        part=\"id\",\n",
    "        channelId=channel_id,\n",
    "        maxResults= 50\n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "        if 'videoId' in item['id']:\n",
    "            video_ids.append(item['id']['videoId'])\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_data(video_ids):\n",
    "    cmt_data = []\n",
    "\n",
    "    request = youtube.commentThreads().list(\n",
    "        part = 'snippet,replies',\n",
    "        videoId = video_ids,\n",
    "        maxResults = 50\n",
    "        )\n",
    "    response = request.execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "        data = dict(comment_id = item['id'],\n",
    "                    channel_id = item['snippet']['channelId'],\n",
    "                    video_id = item['snippet']['videoId'],\n",
    "                    comment_text = item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                    comment_author = item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                    comment_published_date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                    )\n",
    "        cmt_data.append(data)\n",
    " \n",
    "    return cmt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to get video data table details\n",
    "def video_details(video_ids):\n",
    "    video_data = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "                    part = \"snippet,contentDetails,statistics\",\n",
    "                    id = ','.join(video_ids[i+i:50])\n",
    "                    )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            data = dict(channel_name = video['snippet']['channelTitle'],\n",
    "                        video_id = video['id'],\n",
    "                        video_name = video['snippet']['title'],\n",
    "                        channel_id = video['snippet']['channelId'],\n",
    "                        video_description = video['snippet']['description'],\n",
    "                        published_date = video['snippet']['publishedAt'],\n",
    "                        vieew_couunt = video['statistics']['viewCount'],\n",
    "                        like_count = video['statistics']['likeCount'],\n",
    "                        favorite_count = video['statistics']['favoriteCount'],\n",
    "                        comment_count = video['statistics']['commentCount'],\n",
    "                        duration = video['contentDetails']['duration'],\n",
    "                        thumbnail = video['snippet']['thumbnails']['default']['url'],\n",
    "                        caption_status = video['contentDetails']['caption']\n",
    "            )\n",
    "\n",
    "            video_data.append(data)\n",
    "        return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the channel names\n",
    "def channel_names():   \n",
    "    ch_name = []\n",
    "    for i in db.channel_details.find():\n",
    "        ch_name.append(i['channel_name'])\n",
    "    return ch_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL table creation queries\n",
    "# def sql_table_create():\n",
    "\n",
    "create_table_query_channels = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS channels (\n",
    "    channel_id VARCHAR(255),\n",
    "    channel_name TEXT,\n",
    "    channel_views BIGINT,\n",
    "    channel_type VARCHAR(255),\n",
    "    channel_description TEXT,\n",
    "    channel_status TIMESTAMP,\n",
    "    videos_count INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    mycursor.execute(create_table_query_channels)\n",
    "    mydb.commit()\n",
    "    print(\"Tables created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    mydb.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS videos (\n",
    "            channel_name TEXT,\n",
    "            video_id VARCHAR(255),\n",
    "            video_name TEXT,\n",
    "            channel_id VARCHAR(255),\n",
    "            video_description TEXT,\n",
    "            published_date TIMESTAMP,\n",
    "            view_count INT,\n",
    "            like_count INT,\n",
    "            favorite_count INT,\n",
    "            comment_count INT,\n",
    "            duration VARCHAR(255),\n",
    "            thumbnail TEXT,\n",
    "            caption_status BOOLEAN);\n",
    "        \"\"\"\n",
    "\n",
    "try:\n",
    "    mycursor.execute(create_table_query)\n",
    "    mydb.commit()\n",
    "    print(\"Table created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    mydb.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query_comments = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS comment_data (\n",
    "        comment_id VARCHAR(255),\n",
    "        channel_id VARCHAR(255),\n",
    "        video_id VARCHAR(255),\n",
    "        comment_text TEXT,\n",
    "        comment_author VARCHAR(255),\n",
    "        comment_published_date TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    mycursor.execute(create_table_query_comments)\n",
    "    mydb.commit()\n",
    "    print(\"Tables created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    mydb.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a web page on streamlit\n",
    "icon = Image.open(\"D:\\project\\Youtube_logo.png\")\n",
    "st.set_page_config(page_title = \"YouTube Data Harvesting and Warehousing using SQL, MongoDB and Streamlit\",\n",
    "                   page_icon = icon,\n",
    "                   layout = 'wide',\n",
    "                   initial_sidebar_state = 'expanded',\n",
    "                   menu_items = {'About': \"\"\"# This app is used to analyze youtube channel data\n",
    "                                                Created BY *Prakash*\"\"\"})\n",
    "st.title(\" :red[▶️] YouTube Data Harvesting and Warehousing using SQL, MongoDB and Streamlit\")\n",
    "\n",
    "with st.sidebar:\n",
    "    selected = option_menu(None, [\"Home\" , \"Harvest & Store The Data\",\"View\" ],\n",
    "                            icons = [\"house-door-fill\",\"tools\", \"card-text\"],\n",
    "                            default_index = 0 ,\n",
    "                            orientation = \"v\",\n",
    "                            styles={\"nav-link\": {\"font-size\": \"30px\", \"text-align\": \"centre\", \"margin\": \"0px\", \n",
    "                                                \"--hover-color\": \"#33A5FF\"},\n",
    "                                   \"icon\": {\"font-size\": \"30px\"},\n",
    "                                   \"container\" : {\"max-width\": \"6000px\"},\n",
    "                                   \"nav-link-selected\": {\"background-color\": \"#33A5FF\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Home page configuration\n",
    "if selected == \"Home\":\n",
    "    col1, col2 = st.columns(2, gap = 'medium')\n",
    "    col1.markdown(\" ## :green[Domain] : Social Media\" )\n",
    "    col1.markdown(\"## :green[Technologies used] : Python,MongoDB, Youtube Data API, PostgreSql, Plotly, Streamlit\")\n",
    "    col1.markdown(\"## :green[Overview] : Retrieving the Youtube channels data from the Google API, storing it in a MongoDB as data lake, migrating and transforming data into a SQL database, then querying the data and displaying it in the Streamlit app.\")\n",
    "    col2.markdown(\"#   \")\n",
    "    col2.markdown(\"#   \")\n",
    "    col2.markdown(\"#   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Tab configuration for harvesting the dtata and puting it to a data lake\n",
    "\n",
    "if selected == \"Harvest & Store The Data\":\n",
    "    tab1, tab2 = st.tabs([\"$\\huge 📝 EXTRACT $\", \"$\\huge 💾 STORE $\"])\n",
    "\n",
    "    #Harvest Data Tab\n",
    "    with tab1:\n",
    "        st.markdown(\"#    \")\n",
    "        st.write(\"### Enter the Youtube Channel ID :\")\n",
    "        ch_id = st.text_input(\"Hint : Goto channel's home page > Right click > View page source > Find channel_id\")\n",
    "\n",
    "        if ch_id and st.button(\"Harvest Data\"):\n",
    "            ch_details = channel_details(ch_id)\n",
    "            st.write(f'#### Extracted Data from : green[\"{ch_details[0][\"channel_name\"]}\"] channel')\n",
    "            st.table(ch_details)\n",
    "\n",
    "        if st.button(\"Upload to MongoDB\"):\n",
    "            with st.spinner(\"Please wait while we retrive the data for you...\"):\n",
    "                ch_details = channel_details(ch_id)\n",
    "                video_ids = channel_videos(ch_id)\n",
    "                vid_details = video_details(video_ids)\n",
    "\n",
    "\n",
    "\n",
    "                def comments():\n",
    "                    com_d = []\n",
    "                    for i in video_ids:\n",
    "                        com_d += comment_data(i)\n",
    "                        # com_d.append(com_dd)\n",
    "                    return com_d\n",
    "                com_details = comments()\n",
    "                \n",
    "# Extract and put the data into Mongodbcopass or Atlas\n",
    "                collection1 = db.channel_details\n",
    "                collection2 = db.video_details\n",
    "                collection3 = db.comment_details\n",
    "\n",
    "\n",
    "                collection1.insert_many(ch_details)\n",
    "                collection2.insert_many(vid_details)\n",
    "                collection3.insert_many(com_details)\n",
    "\n",
    "\n",
    "                st.success(\" Upload to MongoDB successful !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Tab configuration for storing the data in PostgreSql\n",
    "with tab2:\n",
    "    st.markdown(\"#  \")\n",
    "    st.markdown(\"### Select a Channel to Begin Transform the Data\")\n",
    "    ch_names = channel_names()\n",
    "    user_input = st.selectbox(\"Select Channel\", options = ch_names)\n",
    "\n",
    "    def insert_into_channels():\n",
    "        collections = db.channel_details\n",
    "        query = \"\"\"INSERT INTO channels (channel_id, channel_name, channel_views, channel_type, \n",
    "                    channel_description, channel_status, videos_count) values(%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "        \n",
    "        for i in collections.find({\"channel_name\" : user_input},{'_id' : 0}):\n",
    "                        mycursor.execute(query,tuple(i.values()))\n",
    "                        mydb.commit()\n",
    "\n",
    "    def insert_into_videos():\n",
    "        collections1 = db.video_details\n",
    "        query1 = \"\"\"INSERT INTO videos (channel_name, video_id, video_name, channel_id, video_description, published_date, view_count, \n",
    "                                            like_count, favorite_count, comment_count, duration, thumbnail, caption_status) \n",
    "                                            VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "\n",
    "        for i in collections1.find({\"channel_name\" : user_input},{'_id' : 0}):\n",
    "                values = [str(val).replace(\"'\", \"''\").replace('\"', '\"\"') if isinstance(val, str) else val for val in i.values()]\n",
    "                mycursor.execute(query1, tuple(values))\n",
    "                mydb.commit()\n",
    "\n",
    "\n",
    "    def insert_into_comment_data():\n",
    "        collections1 = db.video_details\n",
    "        collections2 = db.comment_details\n",
    "        query2 = \"\"\"INSERT INTO comment_data (comment_id, channel_id, video_id, comment_text, comment_author,\n",
    "                        comment_published_date) VALUES(%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "\n",
    "        for vid in collections1.find({\"channel_name\" : user_input},{'_id' : 0}):\n",
    "                for i in collections2.find({'video_id': vid['video_id']},{'_id' : 0}):\n",
    "                    mycursor.execute(query2,tuple(i.values()))\n",
    "                    mydb.commit()\n",
    "\n",
    "    if st.button(\"Submit\"):\n",
    "        st.balloons()\n",
    "\n",
    "        try:\n",
    "            insert_into_videos()\n",
    "            \n",
    "            st.success(\"Video details Transformation to PGSQL Successful !!\")\n",
    "        except:\n",
    "            st.error(\"Details already transformed !!\")\n",
    "\n",
    "        try:\n",
    "            insert_into_comment_data()\n",
    "            \n",
    "            st.success(\"Comment details Transformation to PGSQL Successful !!\")\n",
    "        except:\n",
    "            st.error(\"Details already transformed !!\")\n",
    "\n",
    "        try:\n",
    "            insert_into_channels()\n",
    "            \n",
    "            st.success(\"channel details Transformation to PGSSQL Successful !!\")\n",
    "        except:\n",
    "            st.error(\"Details already transformed !!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
